{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "with open('testcases/3/param3.txt') as f:\n",
    "    lines = f.readlines()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train = pd.read_csv(train_path, index_col = 0)    \n",
    "test = pd.read_csv(test_path, index_col = 0)\n",
    "y_train = np.array(train['Length of Stay'])\n",
    "train = train.drop(columns = ['Length of Stay'])\n",
    "data = pd.concat([train, test], ignore_index = True)\n",
    "cols = train.columns\n",
    "cols = cols[:-1]\n",
    "data = pd.get_dummies(data, columns=cols, drop_first=True)\n",
    "data = data.to_numpy()\n",
    "\n",
    "X_train = data[:train.shape[0], :]\n",
    "X_test = data[train.shape[0]:, :]\n",
    "\n",
    "# b = np.zeros((X_train.shape[0], 1))\n",
    "b = np.ones((X_train.shape[0], 1))\n",
    "X_train = np.concatenate((b,X_train), axis=1)\n",
    "\n",
    "# b = np.zeros((X_test.shape[0], 1))\n",
    "b = np.ones((X_test.shape[0], 1))\n",
    "X_test = np.concatenate((b,X_test), axis=1)\n",
    "\n",
    "y_true = pd.get_dummies(y_train)\n",
    "y_true = y_true.to_numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X_train.shape, X_test.shape, y_true.shape, w.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100000, 1633), (10000, 1633), (100000, 8), (1633, 8))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def y_hat(X,w):\n",
    "    return softmax(np.dot(X,w),axis = 1)\n",
    "\n",
    "def gradient(X,w,y_true):\n",
    "    return np.dot(X.T,(y_hat(X,w)-y_true))/X.shape[0]\n",
    "    \n",
    "def loss(X,w,y_true):\n",
    "    k =np.take_along_axis(y_hat(X,w), np.argmax(y_true,axis = 1)[:,None], axis=1)\n",
    "    return -np.sum(np.log(k))/X.shape[0]\n",
    "\n",
    "def fixed_gradient(X,y_true,w,n_iter,lr):\n",
    "    step = 0\n",
    "    while step<n_iter:\n",
    "        w -= lr*gradient(X,w,y_true)\n",
    "        step += 1\n",
    "    return w\n",
    "\n",
    "def adaptive_gradient(X,y_true,w,n_iter,lr):\n",
    "    step = 0\n",
    "    while step<n_iter:\n",
    "        w -= (lr/np.sqrt(step+1))*gradient(X,w,y_true)\n",
    "        step += 1\n",
    "    return w\n",
    "    \n",
    "def alpha_beta_gradient(X,y_true,w,n_iter,alpha,beta,lr):\n",
    "    step = 0\n",
    "    while step<n_iter:\n",
    "        new_lr = lr\n",
    "        grad = gradient(X,w,y_true)\n",
    "        diff = -alpha*new_lr*(np.linalg.norm(grad, ord = 'fro')**2)\n",
    "        curr_loss = loss(X,w,y_true)\n",
    "        new_loss = loss(X,w - new_lr*grad,y_true)\n",
    "\n",
    "        while new_loss - curr_loss> diff:\n",
    "            new_lr *= beta\n",
    "            new_loss = loss(X,w - new_lr*grad,y_true)\n",
    "            diff *= beta\n",
    "        \n",
    "        step+=1\n",
    "        w -= new_lr*gradient(X,w,y_true)\n",
    "    return w"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def mini_batch_gradient(X,y_true,w,n_iter,batch_size,lr):\n",
    "    steps = X.shape[0]//batch_size\n",
    "    i= 0\n",
    "    while i<n_iter:\n",
    "        for j in range(steps):\n",
    "            grad = gradient(X[j*batch_size:(j+1)*batch_size,:],w,y_true[j*batch_size:(j+1)*batch_size,:])\n",
    "            w -= lr*grad\n",
    "        i+=1\n",
    "        print(i,end = '\\t')\n",
    "    return w"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "w = np.zeros(shape = (X_train.shape[1], y_true.shape[1]))\n",
    "w_new = mini_batch_gradient(X_train,y_true,w,n_iter = 50,batch_size = 200,lr = 0.2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\t13\t14\t15\t16\t17\t18\t19\t20\t21\t22\t23\t24\t25\t26\t27\t28\t29\t30\t31\t32\t33\t34\t35\t36\t37\t38\t39\t40\t41\t42\t43\t44\t45\t46\t47\t48\t49\t50\t"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "w_new.flatten()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.19890632, 0.7060623 , 0.1191276 , ..., 0.02092259, 0.08047424,\n",
       "       0.09566638])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "y_test = y_hat(X_test,w_new)\n",
    "y_out = y_test.argmax(axis = 1)+1\n",
    "y_out"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([8, 8, 8, ..., 1, 1, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.savetxt('outputfile.txt', y_out, delimiter='\\n')\n",
    "np.savetxt('weightfile.txt', w_new.flatten(), delimiter='\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit"
  },
  "interpreter": {
   "hash": "c6ad8bbb4d9643c765693fcf4277b69a478f70446993b6b75fa7d8e9c535655f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}