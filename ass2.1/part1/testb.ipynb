{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_data = pd.read_csv('devanagari/train_data_shuffled.csv',header=None)\n",
    "X_train = train_data.iloc[:, :-1].values\n",
    "X_train = X_train.astype(np.float)\n",
    "X_train = X_train / 255\n",
    "y_train = train_data.iloc[:, -1].values\n",
    "y_true= np.array(pd.get_dummies(y_train))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8f6ce4b7d711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'devanagari/train_data_shuffled.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m     \"\"\"\n\u001b[1;32m   1422\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Activation_function():\n",
    "    def __init__(self, activation_function):\n",
    "        self.name = activation_function\n",
    "        self.function = self.activation_function()\n",
    "        self.derivative = self.activation_function_derivative()\n",
    "\n",
    "    def activation_function(self):\n",
    "        if self.name == 'sigmoid':\n",
    "            return lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.name== 'relu':\n",
    "            return lambda x: np.maximum(0, x)\n",
    "        elif self.name == 'tanh':\n",
    "            return lambda x: np.tanh(x)\n",
    "        elif self.name == 'softmax':\n",
    "            return lambda x: np.exp(x - np.max(x,axis = 0)) / np.sum(np.exp(x - np.max(x,axis = 0)),axis = 0)\n",
    "\n",
    "    def activation_function_derivative(self):\n",
    "        if self.name == 'sigmoid':\n",
    "            return lambda x: x * (1 - x)\n",
    "            # return lambda x: self.activation_function(x) * (1 - self.activation_function(x))\n",
    "        elif self.name == 'relu':\n",
    "            return lambda x: 1. * (x > 0)\n",
    "        elif self.name == 'tanh':\n",
    "            return lambda x: 1 - np.power(x, 2)\n",
    "        elif self.name == 'softmax':\n",
    "            # return lambda x: softmax(x,axis = 0)*(1-softmax(x,axis = 0))\n",
    "            return lambda x: x*(1-x)\n",
    "        \n",
    "        \n",
    "\n",
    "def loss_function_CE(y_true, y_pred, derivative):\n",
    "    if not derivative:\n",
    "        return -np.sum(y_true * np.log(y_pred))/y_true.shape[1]\n",
    "    else:\n",
    "        return (y_pred-y_true)/y_true.shape[1]\n",
    "\n",
    "\n",
    "def loss_function_MSE(y_true, y_pred, derivative=False):\n",
    "    if not derivative:\n",
    "        return np.sum((y_true - y_pred) ** 2) / 2\n",
    "    else:\n",
    "        temp = np.sum(2*(y_pred - y_true)*y_pred,axis = 0)\n",
    "        f = 2*(y_pred - y_true)*y_pred*(1-y_pred) - y_pred*temp\n",
    "        return f/y_true.shape[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Neural_Network():\n",
    "\n",
    "    def __init__(\n",
    "        self, input_size, hidden_layer_size_array, output_size, \n",
    "        activation_function, output_activation_function, loss_function\n",
    "    ):\n",
    "        self.input_size = input_size\n",
    "        self.number_of_hidden_layers = len(hidden_layer_size_array)\n",
    "        self.hidden_layer_size_array = hidden_layer_size_array\n",
    "        self.output_size = output_size\n",
    "        self.activation_function = Activation_function(activation_function)\n",
    "        self.output_activation_function = Activation_function(output_activation_function)\n",
    "        self.weights = self.weights_initializer()\n",
    "        self.loss_function = loss_function\n",
    "        self.weights_history = []\n",
    "\n",
    "    def weights_initializer(self):\n",
    "        np.random.seed(1)\n",
    "        weights = []\n",
    "        for i in range(self.number_of_hidden_layers+1):\n",
    "            if i == 0:\n",
    "                weights.append(\n",
    "                    np.random.normal(size = (self.input_size + 1, self.hidden_layer_size_array[i]))\n",
    "                    * np.sqrt(2 / (self.input_size + self.hidden_layer_size_array[i] + 1))\n",
    "                    .astype(np.float32)\n",
    "                )\n",
    "            elif i == self.number_of_hidden_layers:\n",
    "                weights.append(\n",
    "                    np.random.normal(size = (self.hidden_layer_size_array[i - 1] + 1, self.output_size)) \n",
    "                    * np.sqrt(2 / (self.hidden_layer_size_array[i - 1] + self.output_size + 1))\n",
    "                    .astype(np.float32)\n",
    "                )\n",
    "            else:\n",
    "                weights.append(\n",
    "                    np.random.normal(size = (self.hidden_layer_size_array[i - 1] + 1, self.hidden_layer_size_array[i])) \n",
    "                    * np.sqrt(2 / (self.hidden_layer_size_array[i - 1] + self.hidden_layer_size_array[i] + 1))\n",
    "                    .astype(np.float32)\n",
    "                )\n",
    "        return weights\n",
    "    \n",
    "    def feed_forward(self, input_data):\n",
    "        # Feed forward\n",
    "        # Input layer\n",
    "        input_layer = np.array(input_data, ndmin=2).T\n",
    "        \n",
    "        # Hidden layers\n",
    "        a_s = []\n",
    "        z_s = []\n",
    "        for i in range(self.number_of_hidden_layers):\n",
    "            input_layer = np.concatenate((np.ones((1, input_layer.shape[1])), input_layer), axis=0)\n",
    "            z = np.dot(self.weights[i].T, input_layer)\n",
    "            z_s.append(z)\n",
    "            a_s_i = self.activation_function.function(z)\n",
    "            a_s.append(a_s_i)\n",
    "            input_layer = a_s[i]\n",
    "            a_s[i] = np.concatenate((np.ones((1, a_s[i].shape[1])), a_s[i]), axis=0)\n",
    "        \n",
    "        # Output layer\n",
    "        input_layer = np.concatenate((np.ones((1, input_layer.shape[1])), input_layer), axis=0)\n",
    "        z = np.dot(self.weights[-1].T, input_layer)\n",
    "        z_s.append(z)\n",
    "        a_s.append(self.output_activation_function.function(z))\n",
    "        return a_s[-1], a_s, z_s\n",
    "\n",
    "    def back_propagation(self, input_data, y_true):\n",
    "        input_data = np.array(input_data, ndmin=2)\n",
    "        y_pred, a_s, _ = self.feed_forward(input_data)\n",
    "\n",
    "        # Output layer\n",
    "        y_true = np.array(y_true, ndmin=2).T\n",
    "        delL_dzs = [self.loss_function(y_true, y_pred, derivative=True)]\n",
    "        delL_das = [np.dot(self.weights[-1], delL_dzs[-1])]\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(self.number_of_hidden_layers-1, -1, -1):\n",
    "            delL_dz_i = delL_das[-1]*self.activation_function.derivative(a_s[i])\n",
    "            delL_dzs.append(delL_dz_i[1:])\n",
    "            delL_das.append(np.dot(self.weights[i], delL_dzs[-1]))\n",
    "        \n",
    "        delL_dzs.reverse()\n",
    "        delL_dws = []\n",
    "        for i in range(self.number_of_hidden_layers+1):\n",
    "            if i==0:\n",
    "                input_data = np.c_[np.ones(input_data.shape[0]), input_data]\n",
    "                delL_dws.append(np.dot(input_data.T, delL_dzs[i].T))\n",
    "            else:\n",
    "                delL_dws.append(np.dot(a_s[i-1], delL_dzs[i].T))\n",
    "        \n",
    "        return delL_dws\n",
    "\n",
    "    def train(self, input_data, y_true,epochs,batch_size,learning_rate,adaptive_learning_rate = False):\n",
    "        # Training\n",
    "        iter = 0\n",
    "        for i in range(epochs):\n",
    "            for j in range(0, len(input_data), batch_size):\n",
    "                if j + batch_size > len(input_data):\n",
    "                    batch_input_data = input_data[j:]\n",
    "                    batch_y_true = y_true[j:]\n",
    "                else:\n",
    "                    batch_input_data = input_data[j:j+batch_size]\n",
    "                    batch_y_true = y_true[j:j+batch_size]\n",
    "                del_w = self.back_propagation(batch_input_data, batch_y_true)\n",
    "                if adaptive_learning_rate == True:\n",
    "                    learning_rate = learning_rate * np.sqrt(1/(iter+1))\n",
    "                for k in range(len(self.weights)):\n",
    "                    self.weights[k] -= learning_rate * del_w[k]\n",
    "                iter += 1\n",
    "                if i==0 and iter == 4:\n",
    "                    self.weights_history.append(self.weights)\n",
    "            if i==4:\n",
    "                self.weights_history.append(self.weights)\n",
    "            # if (i+1)%50==0:\n",
    "            print(f'Epoch:{i+1}', self.evaluate(input_data, y_true))\n",
    "    def predict(self, input_data):\n",
    "        input_data = np.array(input_data, ndmin=2)\n",
    "        y_pred, _, _ = self.feed_forward(input_data)\n",
    "        return y_pred\n",
    "\n",
    "    def evaluate(self, input_data, y_true):\n",
    "        y_pred = self.predict(input_data)\n",
    "        return self.loss_function(y_true.T, y_pred,False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nn = Neural_Network(input_size = 1024,\n",
    "    hidden_layer_size_array = [512,256,128],\n",
    "    output_size = 46,\n",
    "    activation_function = 'sigmoid',\n",
    "    output_activation_function = 'softmax',\n",
    "    loss_function = loss_function_CE,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nn.train(\n",
    "    X_train, y_true,\n",
    "    epochs=5,batch_size=100,\n",
    "    learning_rate=0.01,\n",
    "    adaptive_learning_rate=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import r2_score\n",
    "for i in range(4):\n",
    "    k = np.load(f'checker_weights/multiclass_dataset/ac_w_{i+1}.npy')\n",
    "    # l = nn.weights_history[1][i]\n",
    "    l = nn.weights[i] \n",
    "    # print(np.max(np.abs(l-k)/k))\n",
    "    print(r2_score(k,l))\n",
    "\n",
    "# for i in range(4):\n",
    "#     k = np.load(f'checker_weights/multiclass_dataset/ac_w_{i+1}_iter.npy')\n",
    "#     l = nn.weights_history[0][i] \n",
    "#     # print(np.max(np.abs(l-k)/k))\n",
    "#     print(r2_score(k,l))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = nn.predict(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred.shape, y_true.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss_function_MSE(y_true.T, y_pred,False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test = pd.read_csv('devanagari/public_test.csv', header=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = nn.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train, y_pred, average='macro')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = np.arange(9).reshape(3,3)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.12 64-bit"
  },
  "interpreter": {
   "hash": "7a3d88c904243d2c3f246166597f86d1c0a39f3d97496d1fe394945d0c6d436d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}